{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name : Alireza Asadbeygi \n",
    "\n",
    "### Review group 5 \n",
    "\n",
    "### topic :Supplemental Reading - JOIN or MERGE Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This article gives review the three main types of merging or joining data frmaes  \n",
    "or tables, and has different names for each one. also the article talk about some  \n",
    "technical terms in data science that me intersting to hear about here.  \n",
    "following is a short summary of this article which covers very important points. \n",
    "(( since the syntac in the article is based on R, so the codes are not provided )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the real world data science projects, data come from different sources \n",
    "and different tables. This data which include multiple data is called `rational` data.  \n",
    "so in order to integrate these different data frames,these important methods must be  \n",
    "considered: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutating Joins (Inner Joins): This technique allows us to alter or mutate our dataset, \n",
    "keeping only the rows with matching keys in both datasets. This process serves as a  \n",
    "potent tool for extracting commonalities, and helpd in identifying shared elements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering Joins (Left Joins): as seen in the lecture notes, filtering joins maintain all rows  \n",
    "from the left dataset while incorporating matched data from the right dataset.  \n",
    "This method proves invaluable when inclusivity is crucial to the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Operations (Anti Joins): keeping the concept of exclusivity, set operations bring attention  \n",
    "to the rows unique to the left dataset, excluding those with matches in the right dataset.  \n",
    "This method is important and useful for isolating distinctive elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learnign these operations is really essential for data scientists and analysts.  \n",
    "These techniques empower professionals to handle datasets precisely,  \n",
    "unraveling intricate relationships between different sources of data, and definitely  \n",
    "an important part of data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- What is the primary purpose of a filtering join (left join) in relational data merging?\n",
    "\n",
    "A. Highlight unique rows in the left dataset\n",
    "B. Extract only the rows with matching keys in both datasets\n",
    "C. Preserve all rows from the left dataset, filling in with matched data from the right dataset\n",
    "\n",
    "Answer- C. Preserve all rows from the left dataset, filling in with matched data from the right dataset\n",
    "\n",
    "2-Set operations (anti joins) are employed to emphasize the rows that are unique to the right dataset.\n",
    "\n",
    "A. True\n",
    "B. False\n",
    "Answer -B. False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is aggregate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FENGYANG HAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas groupby aggregate function, aggregate using one or more operations over the specified axis.\n",
    "\n",
    "It mainly has two 4 parameters:\n",
    "func: it can be a function, string, dictionary, or list of string/functions\n",
    "\n",
    "axis: {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "\n",
    "Usage Example:\n",
    "```python\n",
    "df.groupby(['A','D'],dropna = False).\\\n",
    "aggregate(B_min=('B', 'min'), \n",
    "            B_max=('B', 'max'),\n",
    "\n",
    "            C_min=('C', 'min'),\n",
    "            C_max=('C', 'max'),                \n",
    "            C_my_func=('C', my_func)).\\\n",
    "reset_index()\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "1. You group df by different values in column A and B, and keep the NaN value in them. \n",
    "2. Then, you apply aggregate function to calculate some metrics on B and C.\n",
    "3. Take B as an example, you calculate the min and max of it by specifying B column, and name them as B_min and B_max.\n",
    "4. Take C as an example, you calculate the min and max of it by specifying C column, and name them as C_min and C_max.\n",
    "5. You can also apply your own function to calculate the metrics, and name it as C_my_func.\n",
    "6. Finally, you reset the index of the dataframe to avoid multi-index which might cause some problems in searching and sorting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance\n",
    "\n",
    "When aggregating using the aggregate method, the func parameter can accept both built-in methods in Pandas and user-defined functions. Furthermore, these methods and functions can be applied to each column, multiple functions or methods can be applied to the same column, or different functions or methods can be applied to different columns, greatly enhancing the flexibility of data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True or False Question\n",
    "\n",
    "Q1. In pandas, the groupby method always requires the use of the aggregate function to summarize the grouped data.\n",
    "\n",
    "\n",
    "Answer: False\n",
    "\n",
    "\n",
    "You can also use other methods like sum, mean, etc., directly after groupby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. In pandas, when using the groupby method, the columns you group by become the new index of the returned object, unless as_index is set to False.\n",
    "\n",
    "Answer: True\n",
    "\n",
    "If you specified more than one column to group by, the new index will be a multi-index. As introduced in the recording, we'd better reset the index after groupby to avoid multi-index which might cause some problems in searching and sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for Missing Values\n",
    "\n",
    "### Week 05 Summary Review\n",
    "\n",
    "### Mark Godwin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to identify Missing value in a Series or a DataFrame.  We can accomplish this with a few methods available to us using Pandas.  The `.isnull()` method can be used with Panda Series to convert the entire series into a `boolean`, displaying `True` or `False` values.  Missing values will display as True, and False means that the value is present.  `.isna()` is another method that accomplishes the same task, but can be used in both Panda Series and Pandas DataFrames.\n",
    "\n",
    "We can summarize the number of missings by using `.isna().sum()`.  To view the proportion and see the percentage of each column or row that has missing values, we can use `.isna().mean()`.\n",
    "\n",
    "To create a Complete Case, where all missings are removed, we can use the `.dropna()` method.  This will return a DataFrame free of missings, and display all values present. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Which line of code will sum all the missings of all columns in a Panda DataFrame `df`?\n",
    "\n",
    "A. df.isna().sum()\n",
    "\n",
    "B. df.isna().mean()\n",
    "\n",
    "C. df.dropna()\n",
    "\n",
    "D. df.isnull()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Which line of code will sum the missings of all  rows of the same DataFrame `df` ?\n",
    "\n",
    "A. df.isna().mean(axis=0)\n",
    "\n",
    "B. df.isna().sum\n",
    "\n",
    "C. df.isna().sum(axis=1)\n",
    "\n",
    "D. df.dropna().mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `groupby()`, split-apply-combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yixiao Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.groupby()` method of a dataframe object in pandas works under the concept of **split-apply-combine**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example\n",
    "df.groupby(['A'], dropna=False).\\\n",
    "aggregate(x_numrows = ('x', 'size'),\n",
    "          x_nonmissing = ('x', 'count'),\n",
    "          x_mean = ('x', 'mean'),\n",
    "          x_std = ('x', 'std'),\n",
    "          x_sem = ('x', 'sem'),\n",
    "          x_unique = ('x', 'nunique')).\\\n",
    "reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code example, **split** corresponds to the part, `.groupby(['A'], dropna=False)`, which conceptually is`.groupby(grouping variable, ...)`. Under that hood, it generates a bunch of data frames(groups) separated from the original data frame according to the different values of the grouping variable.  \n",
    "\n",
    "**Apply**(apply aggregation method) and **combine** correspond to the part: `aggregate(x_numrows = ('x', 'size'), ...)`,  which conceptually is `.aggregate(named_column = ('grouped/studied variable', 'aggregation method'), ...)`.   \n",
    "\n",
    "Each aggregation method returns a single summary statistic calculated for a column(grouped variable) of a single group separated from `groupby()` method. **Apply** will loop through all the data frames(all the groups) generated by `groupby()` to apply the aggregation method for the grouped variable.\n",
    "\n",
    "**Combine** then combines all the single summary statistics for one column(a grouped variable) of each group calculated by a aggregation function into a column(named column), and combines all the named columns(corresponding to all the pairs of a grouped variable + a aggregation method) into a data frame.\n",
    "\n",
    "This data frame is just the summary of all the statistics(the columns you named) for each group (a row in the data frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PS**: Aggregation method is to aggregate all the data you're interested in into a single value/statistic, it could be `sum`, `mean`, `std`, `sem` or any summary statistic you want to know about the data.  \n",
    "\n",
    "Below are some examples of aggregation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean() # caculate the means for all the columns in the data frame.\n",
    "\n",
    "df['A'].mean() # calculate the mean for a specified column, A, in the data frame.\n",
    "\n",
    "df.groupby(['G'], dropna=False).\\\n",
    "aggregate(x_mean = ('A', 'mean')). # caculate the mean for a specified column, A, for each group(data frame) separated from df by the unique values of G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pandas library, what is the primary purpose of the `groupby()` method?\n",
    "\n",
    "a) To sort data in ascending or descending order based on one or more columns.\n",
    "\n",
    "b) To merge or concatenate two or more DataFrames.\n",
    "\n",
    "c) To split data into groups based on some criteria and then apply a function to each group independently.\n",
    "\n",
    "d) To reshape the DataFrame from a wide format to a long format.\n",
    "\n",
    "Answer: c) To split data into groups based on some criteria and then apply a function to each group independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In pandas, after using the `groupby()` method on a DataFrame, the result is always another DataFrame with the same number of rows as the original.\n",
    "\n",
    "a) True\n",
    "\n",
    "b) False\n",
    "\n",
    "Answer: b) False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing Series and DataFrames\n",
    "## Tate Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating summary statistics is a crucial first step when beginning to explore a dataset. Pandas includes a number of useful methods whose behavior is important to understand.\n",
    "\n",
    "Because Pandas is built off of Numpy, many of these methods look and function the same way. `.mean()`, `.min()`, and `.max()` calculate the average, minimum value, and maximum value for the series or DataFrame. \n",
    "\n",
    "The `.var()` and `.std()` methods, however, differ from their Numpy counterparts in one notable respect. The Pandas versions are superior for data analysis in that the default degrees of freedom argument is set to 1, meaning that it calculates the **unbiased** estimate of these parameters.\n",
    "\n",
    "It is also worth keeping in mind that summary methods will automatically remove any missing values before running the calculation - this is captured by the `skipna` argument, which by default is set to `True`. These summary values cannot be calculated if there are any missing values.\n",
    "\n",
    "Summary methods can also be applied to entire DataFranes and across rows as well as individual columns. Because DataFrames can contain multiple data types, applying these methods across the entirety of the DataFrame will only count numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) TRUE or FALSE: The default value for the argument `ddof` in the Pandas versions of `.var()` and `.std()` is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Which of the following best describes the behavior when applying summary methods **across rows** of a DataFrame that has both numeric and string (object) columns? See the line of code below for an example.\n",
    "\n",
    "`df.mean(axis = 1)`\n",
    "\n",
    "A. The summary statistic will be calculated only using non-numeric columns.\n",
    "\n",
    "B. The summary statistic will be calculated only using numeric columns.\n",
    "\n",
    "C. An error will be returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>[Click here for answers]</summary>\n",
    "1. False\n",
    "2. B\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Megan Underwood \n",
    "\n",
    "Reading in .csv and .url files: \n",
    "\n",
    "Summary:  \n",
    "\n",
    "Reading .csv and .url files refers to the process of extracting data from files with these specific formats. CSV or Comma-Separated Values files are a common format for storing structured data, such as spreadsheets and databases. Each line in a .CSV file typically represents a row of data, and values within the row are separated by commas. .CSV files are used for data exchange between different software applications. Many data analysis tools and programming languages (e.g., Python, R, Excel) have built-in support for reading and writing .CSV files. URL or Uniform Resource Locator files are a plain text file that contains a URL or web address. URL files help users save and organize their favorite websites or web resources. Clicking on a .URL file will open the associated website in a web browser.  \n",
    "\n",
    "Questions: \n",
    "\n",
    "Question 1: What is the primary purpose of reading a .csv file? \n",
    "\n",
    "A) To store bookmarks and website links. B) To exchange structured data between different software applications. C) To create backups of databases. D) To perform advanced data analysis. \n",
    "\n",
    "Correct Answer: B) To exchange structured data between different software applications. \n",
    "\n",
    "Question 2: What is the main function of a .url file? \n",
    "\n",
    "A) To open a specific web page in a web browser. B) To create structured data for analysis. C) To store information in a spreadsheet. D) To exchange data between different web browsers. \n",
    "\n",
    "Correct Answer: A) To open a specific web page in a web browser. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 5 \n",
    "\n",
    "## Ellen Gaus\n",
    "\n",
    "### Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.concat()` is the function to combine data frames. The first listed object will appear first (as in on top), and the second listed object will appear second (on the bottom). \n",
    "\n",
    "The dataframes should be the same size and share the same column names in order to stack the dataframes on top of one another, resulting in a taller dataframe. If the dataframes are different sizes and do not share the same column names, `pd.concat()` will bind the columns, resulting in a wider dataframe as opposed to a taller dataframe.\n",
    "\n",
    "The first listed object will become the left dataframe, and the second listed object will be the right dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.concat()` by itself will vertically stack dataframes ontop of one another. As such, the index will repeat with each dataframe. Adding the argument ignore_index=True will create a unique index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.concat( [dataframe1, dataframe2] ) is the same as pd.concat( [dataframe1, dataframe2], axis=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review questions with answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: Which of the following will result in a new dataframe with a unique `.index` attribute?\n",
    "\n",
    "1 - pd.concat( [dataframe1, dataframe2])\n",
    "2 - pd.concat( [dataframe1, dataframe2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: pd.concat( [dataframe1, dataframe2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: True or False - concatenate can combine dataframes of different sizes\n",
    "\n",
    "1 - True\n",
    "2 - False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in excel files\n",
    "\n",
    "## Segol\n",
    "\n",
    "\n",
    "The pd.read_csv() method is used to retrieve data from a CSV file and formats that data into a Pandas data frame. This method is similar to read_excel(), except excel files have multiple sheets and CSV files only have one sheet. The method accepts the following arguements:\n",
    "* filepath_or_buffer: the location of the file, and the only obligatory arguement. \n",
    "* sep: separator, default is a comma (', ') for comma seperated values (CSV).\n",
    "* header: The row number that contains the column headers.\n",
    "* usecols: Accepts a list of strings that refer to the column names to be used so that one can select specific columns.\n",
    "* nrows: Accepts an integer that refers to how many rows are used from the CSV file.\n",
    "* index_col: Used to assign column names to the index\n",
    "* skiprows: Accepts a range of rows to include in the dataset if they were previously left out in the inital read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows an example of the read_csv() method with only the one obligatory arguement and the default parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-6.240387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-4.860661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.066712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.635156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-4.893876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.155377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.818466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.294759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.398190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.527589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A   B   C         x\n",
       "0    a1  b0  C1 -6.240387\n",
       "1    a1  b0  C1 -4.860661\n",
       "2    a1  b0  C1 -5.066712\n",
       "3    a1  b0  C1 -5.635156\n",
       "4    a1  b0  C1 -4.893876\n",
       "..   ..  ..  ..       ...\n",
       "125  a2  b1  C2  1.155377\n",
       "126  a2  b1  C2  2.818466\n",
       "127  a2  b1  C2  3.294759\n",
       "128  a2  b1  C2  2.398190\n",
       "129  a2  b1  C2  2.527589\n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv('hw05_prob_01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, setting the index_col to 0 makes the zeroth column (A) the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-6.240387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-4.860661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.066712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.635156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-4.893876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.155377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.818466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.294759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.398190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.527589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     B   C         x\n",
       "A                   \n",
       "a1  b0  C1 -6.240387\n",
       "a1  b0  C1 -4.860661\n",
       "a1  b0  C1 -5.066712\n",
       "a1  b0  C1 -5.635156\n",
       "a1  b0  C1 -4.893876\n",
       "..  ..  ..       ...\n",
       "a2  b1  C2  1.155377\n",
       "a2  b1  C2  2.818466\n",
       "a2  b1  C2  3.294759\n",
       "a2  b1  C2  2.398190\n",
       "a2  b1  C2  2.527589\n",
       "\n",
       "[130 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv('hw05_prob_01.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also limit the number of rows included. Below, only the first 5 rows are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-6.240387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-4.860661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.066712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.635156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-4.893876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C         x\n",
       "0  a1  b0  C1 -6.240387\n",
       "1  a1  b0  C1 -4.860661\n",
       "2  a1  b0  C1 -5.066712\n",
       "3  a1  b0  C1 -5.635156\n",
       "4  a1  b0  C1 -4.893876"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv('hw05_prob_01.csv', nrows = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also exclude rows. The skiprows parameter accepts an integer that refers to the first n rows that will be skipped. However, you must set the header to None when using this method, or the first row of values will be assigned to the column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>b0</th>\n",
       "      <th>C1</th>\n",
       "      <th>-4.8606610695201224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.066712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.635156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-4.893876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-6.626860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.162203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.155377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.818466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.294759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.398190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.527589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     a1  b0  C1  -4.8606610695201224\n",
       "0    a1  b0  C1            -5.066712\n",
       "1    a1  b0  C1            -5.635156\n",
       "2    a1  b0  C1            -4.893876\n",
       "3    a1  b0  C1            -6.626860\n",
       "4    a1  b0  C1            -5.162203\n",
       "..   ..  ..  ..                  ...\n",
       "123  a2  b1  C2             1.155377\n",
       "124  a2  b1  C2             2.818466\n",
       "125  a2  b1  C2             3.294759\n",
       "126  a2  b1  C2             2.398190\n",
       "127  a2  b1  C2             2.527589\n",
       "\n",
       "[128 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv('hw05_prob_01.csv', skiprows=2,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skiprows can also accept a range of numbers to ensure that you don't skip the first row containing the column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-6.240387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-4.860661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-4.893876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-6.626860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>b0</td>\n",
       "      <td>C1</td>\n",
       "      <td>-5.162203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.155377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.818466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.294759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.398190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.527589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A   B   C         x\n",
       "0    a1  b0  C1 -6.240387\n",
       "1    a1  b0  C1 -4.860661\n",
       "2    a1  b0  C1 -4.893876\n",
       "3    a1  b0  C1 -6.626860\n",
       "4    a1  b0  C1 -5.162203\n",
       "..   ..  ..  ..       ...\n",
       "123  a2  b1  C2  1.155377\n",
       "124  a2  b1  C2  2.818466\n",
       "125  a2  b1  C2  3.294759\n",
       "126  a2  b1  C2  2.398190\n",
       "127  a2  b1  C2  2.527589\n",
       "\n",
       "[128 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv('hw05_prob_01.csv', skiprows=[3,4],header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>C1</td>\n",
       "      <td>-0.101313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.162981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.385787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>C1</td>\n",
       "      <td>-0.655076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>b1</td>\n",
       "      <td>C1</td>\n",
       "      <td>-0.949339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.155377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.818466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.294759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.398190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>a2</td>\n",
       "      <td>b1</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.527589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2         3\n",
       "0    a1  b1  C1 -0.101313\n",
       "1    a1  b1  C1  1.162981\n",
       "2    a1  b1  C1  0.385787\n",
       "3    a1  b1  C1 -0.655076\n",
       "4    a1  b1  C1 -0.949339\n",
       "..   ..  ..  ..       ...\n",
       "106  a2  b1  C2  1.155377\n",
       "107  a2  b1  C2  2.818466\n",
       "108  a2  b1  C2  3.294759\n",
       "109  a2  b1  C2  2.398190\n",
       "110  a2  b1  C2  2.527589\n",
       "\n",
       "[111 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv('hw05_prob_01.csv', skiprows=20,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True or False: In the method pd.read_csv(), the default value of the parameter 'header' is 1.\n",
    "a) True\n",
    "b) False\n",
    "\n",
    "Answer: b) False, the default is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't want to include the first 20 rows of your CSV file. Which parameter would be most appropiate to achieve that result?\n",
    "a) nrows\n",
    "b) index_col\n",
    "c) skiprows\n",
    "d) sep\n",
    "\n",
    "Answer: c) skiprows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPINF 2100\n",
    "## Review: Wave 1, Group 5 \n",
    "\n",
    "### Understanding Unique Values\n",
    "\n",
    "## Sarah Scott\n",
    "\n",
    "#### Overview: \n",
    "\n",
    "Many summary methods important to Exploratory Data Analysis require the ability to identify the **unique values** in a Pandas series or DataFrame. For small, numerical data sets that are easy to quickly summarize through the visualization of the data, this might seem like an unimportant step. However, for large data sets or categorical/string variables, it is an essential one.\n",
    "\n",
    "We can retrieve the number of unique values using `.nunique()`, which will **count** the number (n) of unique values in the series or column. Comparing this number to the `.size` attribute will provide us with a clear understanding of how many unique values are in the series/column. \n",
    "  \n",
    "In a similar vein, the `.unique()` method lists the unique values in a series/column. This allows us to identify the unique elements themselves. \n",
    "\n",
    "One important Pandas method that focuses on unique values is `.value_count()`. This method counts the number of times a unique value occurs, and tells us how many times the values appear per value. \n",
    "\n",
    "*Important Note*: By default, these methods do **not** count missing values, so `dropna=False` is often used in conjunction with this method. \n",
    "\n",
    "#### Example: \n",
    "\n",
    "In the below example, we identify the use of `.unique()`, `.nunique()`, and `.value_count()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_fellowship = pd.Series( [ 'Hobbit', 'Hobbit', 'Hobbit', 'Hobbit', 'Wizard', 'Man', 'Man', 'Elf', 'Dwarf' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "5\n",
      "['Hobbit' 'Wizard' 'Man' 'Elf' 'Dwarf']\n"
     ]
    }
   ],
   "source": [
    "print(the_fellowship.size)\n",
    "print(the_fellowship.nunique())\n",
    "print(the_fellowship.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we identify there are 9 values to the series, `the_fellowship`. However, using `.nunique()`, we identified only five of those values are unique. We are able to identify what those unique variables are using `.unique()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hobbit    4\n",
       "Man       2\n",
       "Wizard    1\n",
       "Elf       1\n",
       "Dwarf     1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "the_fellowship.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.value_counts()`, we can identify how many values are associated with each variable - in `the_fellowship`, there are four hobbits, two men, one wizard, one elf, and one dwarf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** TRUE/FALSE: The `.unique()` method only retrieves the *number* of unique values in a series/column. It does not list the unique values.  \n",
    "\n",
    "**ANSWER**: False. The `.unique()` method *does* list the unique values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** You are a teacher with a class of 100 students. You have created a DataFrame (`class_list`) of their names with three columns: first name (`first`), Last Name (`last`) and Full Name (`full`). You want to identify how many students have the same first name. What method would you use? \n",
    "\n",
    "* A `class_list.first.nunique()`\n",
    "* B `class_list.first.unique()` \n",
    "* C `first.nunique()`\n",
    "* D `class_list.full.nunique()`\n",
    "\n",
    "**ANSWER:** A, `class_list.first.nunique()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both join and merge are fundamental operations in data manipulation and database design. They are used to combine datasets based on common column values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIE ZHANG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining datasets:\n",
    "\n",
    "The join method in pandas is used to combine DataFrames based on index values. By default, join operates on indices, but you can also join on columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "K0   A0   B0   C0   D0\n",
      "K1   A1   B1  NaN  NaN\n",
      "K2   A2   B2   C2   D2\n",
      "K3  NaN  NaN   C3   D3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'A': ['A0', 'A1', 'A2'],\n",
    "    'B': ['B0', 'B1', 'B2']\n",
    "}, index=['K0', 'K1', 'K2'])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'C': ['C0', 'C2', 'C3'],\n",
    "    'D': ['D0', 'D2', 'D3']\n",
    "}, index=['K0', 'K2', 'K3'])\n",
    "\n",
    "result = df1.join(df2, how='outer')  # 'outer' join includes all indices from both DataFrames.\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets:\n",
    "\n",
    "The merge function is more flexible than join and is primarily used to combine datasets based on column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key    A    B    C    D\n",
      "0  K0   A0   B0   C0   D0\n",
      "1  K1   A1   B1  NaN  NaN\n",
      "2  K2   A2   B2   C2   D2\n",
      "3  K3  NaN  NaN   C3   D3\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'key': ['K0', 'K1', 'K2'],\n",
    "    'A': ['A0', 'A1', 'A2'],\n",
    "    'B': ['B0', 'B1', 'B2']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'key': ['K0', 'K2', 'K3'],\n",
    "    'C': ['C0', 'C2', 'C3'],\n",
    "    'D': ['D0', 'D2', 'D3']\n",
    "})\n",
    "\n",
    "result = pd.merge(df1, df2, on='key', how='outer')\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge types:\n",
    "\n",
    "Inner (default): Only rows with matching keys in both dataframes are returned.\n",
    "\n",
    "Outer: All rows from both dataframes are returned. Missing values are filled with NaN.\n",
    "\n",
    "Left: All rows from the left dataframe and any rows from the right dataframe with matching keys are returned.\n",
    "\n",
    "Right: All rows from the right dataframe and any rows from the left dataframe with matching keys are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance in Database Design:\n",
    "\n",
    "Combining datasets using join or merge ensures that relationships between data are maintained. This is particularly crucial when working with relational databases where referential integrity is a concern.\n",
    "\n",
    "Instead of storing repetitive data, databases can store related data in separate tables and combine them when necessary. This makes operations like updates more efficient and reduces storage needs.\n",
    "\n",
    "Using joins and merges allows for flexibility in querying. You can obtain a holistic view from multiple tables, which would otherwise be scattered across the database.\n",
    "\n",
    "By designing databases where related data is separated into different tables and then combined when necessary, you reduce the risk of data redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values MISSINGS\n",
    "\n",
    "When join or merge datasets, there are scenarios where certain records do not have corresponding matches in the other dataset. In such cases, the result will contain missing values. The nature and location of these missing values depend on the type of join/merge used.\n",
    "\n",
    "Inner Join/Merge: Only the records that have matching values in both datasets will be present in the result. Records that are in one dataset but not in the other will be excluded.There will be no missing values in the result because all non-matching records are omitted.\n",
    "\n",
    "Outer Join/Merge: All records from both datasets will be present in the result. If a record in one dataset does not have a match in the other dataset, the result will have missing values (NaN in pandas) for all columns of the dataset where the match is missing.\n",
    "\n",
    "Left Join/Merge: All records from the left dataset and only the matching records from the right dataset will be present. If a record in the left dataset doesn't have a corresponding match in the right dataset, the result will have missing values for all columns of the right dataset.\n",
    "\n",
    "Right Join/Merge: All records from the right dataset and only the matching records from the left dataset will be present. If a record in the right dataset doesn't have a corresponding match in the left dataset, the result will have missing values for all columns of the left dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The differences between pandas' JOIN/MERGE and SQL's JOIN/MERGE operations.\n",
    "\n",
    "**Functionality**\n",
    "\n",
    "pandas' join and merge are primarily for data combination.\n",
    "SQL's JOIN is also for data combination.\n",
    "SQL's MERGE serves a dual purpose of synchronization (insert, update, delete based on join conditions).\n",
    "\n",
    "**Use Cases:**\n",
    "\n",
    "pandas operations are best suited for data analysis and manipulation in a Python environment.\n",
    "SQL operations are best for managing and querying data within relational databases.\n",
    "Immutable vs Mutable Operations:\n",
    "\n",
    "By default, pandas' operations return new DataFrames and do not modify the original ones.\n",
    "SQL's MERGE modifies the target table directly.\n",
    "\n",
    "**Syntax and Environment:**\n",
    "\n",
    "pandas operates within Python using method calls on DataFrames.\n",
    "SQL's operations use declarative syntax and are executed within a database environment.\n",
    "In essence, while both pandas and SQL offer join and merge-like operations, the context, usage, and underlying mechanics can differ significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Choice Questions:\n",
    "\n",
    "1.Which parameter in pandas' merge function allows you to specify the type of merge to be performed?\n",
    "a) type\n",
    "b) kind\n",
    "c) how\n",
    "d) method\n",
    "\n",
    "2.If you are performing a LEFT JOIN between df1 and df2 and a key is present in df1 but not in df2, the resulting dataframe will have:\n",
    "a) No missing values.\n",
    "b) Missing values for all columns of df1.\n",
    "c) Missing values for all columns of df2.\n",
    "d) An error is raised.\n",
    "\n",
    "### True/False Questions:\n",
    "\n",
    "1.If you perform a RIGHT JOIN in pandas between df1 and df2, and a certain key exists in df1 but not in df2, the resultant DataFrame will contain missing values for columns from df2.\n",
    "\n",
    "A. True\n",
    "B. False\n",
    "\n",
    "2.After an INNER JOIN, the resulting DataFrame will never have missing values, irrespective of the DataFrames being joined.\n",
    "\n",
    "A. True\n",
    "B. False\n",
    "\n",
    "**Answers:**\n",
    "\n",
    "Multiple Choice:\n",
    "\n",
    "c) how\n",
    "c) Missing values for all columns of df2.\n",
    "\n",
    "True/False:\n",
    "\n",
    "False\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 5\n",
    "\n",
    "## James Noyama\n",
    "\n",
    "### Filter Pandas with Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two methods that allow one to filter Pandas using strings: `.isin()` and `.str.contains()`.\n",
    "\n",
    "`.isin()` can be used to filter a Pandas DataFrame based on particular values. Using the `.isin()` method makes filtering more readable than having multiple `|` operators. If multiple string conditions are being searched for, a list must be given to the `isin()` method. The `isin()` method also allows searching for numeric values.\n",
    "\n",
    "`.str.contains()` looks for a pattern within a string and returns all values containing that pattern. However, if the pattern being searched for is too small (e.g. 'a'), all values containing that string will be returned. \n",
    "\n",
    "The `str.contains()` method can also be used to search for periods, white space, and other characters. To do so, one must use the pattern that escapes special characters `\\\\`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review questions and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** TRUE of FALSE: The following two lines of code will result in the same DataFrame filter.\n",
    "\n",
    "df.loc[ ( df.Animals == 'Birds' ) | ( df.Animals == 'Reptiles' ), : ]\n",
    "\n",
    "df.loc[ df.Animals.isin( [ 'Birds', 'Reptiles' ] ), : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Which of the following will search for a string containing a period `.`?\n",
    "1) df.Animals.str.contains( ' . ' )\n",
    "2) df.Animals.str.contains( ' \\\\\\ . ' )\n",
    "3) df.Animals.isin( ' . ' )\n",
    "4) df.Animals.isin( ' \\\\\\ . ' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "2) df.Animals.str.contains( ' \\\\\\ . ' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
